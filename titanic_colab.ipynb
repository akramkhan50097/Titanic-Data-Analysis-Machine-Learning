{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55d852d3",
   "metadata": {},
   "source": [
    "# Titanic: Data Analysis & Machine Learning (Google Colab)\n",
    "\n",
    "**Objective:** Build a simple machine learning pipeline to predict passenger survival using the Titanic dataset. This notebook is ready to open in Google Colab.\n",
    "\n",
    "Sections:\n",
    "1. Setup\n",
    "2. Load data (seaborn)\n",
    "3. Exploratory Data Analysis (EDA)\n",
    "4. Preprocessing\n",
    "5. Model training (Random Forest)\n",
    "6. Evaluation & Conclusion\n",
    "\n",
    "You can upload this notebook to Google Drive and open it with Colab: `File > Upload notebook` or `Open notebook > GitHub/Drive`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154a6163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup (Colab-ready)\n",
    "# If running in Colab and packages are missing, uncomment the following lines to install them.\n",
    "# !pip install seaborn scikit-learn pandas matplotlib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "sns.set()\n",
    "\n",
    "print('Libraries imported successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33707343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Titanic dataset from seaborn\n",
    "titanic = sns.load_dataset('titanic')\n",
    "titanic.head()\n",
    "\n",
    "# Quick info\n",
    "titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b92284a",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "Let's look at distributions and relationships between features and survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1302d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA plots\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.countplot(x='survived', data=titanic)\n",
    "plt.title('Survival Count')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.countplot(x='class', hue='survived', data=titanic)\n",
    "plt.title('Survival by Class')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.boxplot(x='survived', y='age', data=titanic)\n",
    "plt.title('Age vs Survival')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866f806e",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "We'll select a subset of features, handle missing values, encode categoricals, and prepare data for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99142543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and preprocess\n",
    "df = titanic.copy()\n",
    "features = ['pclass','sex','age','sibsp','parch','fare','embarked']\n",
    "df = df[features + ['survived']]\n",
    "\n",
    "# Handle missing values: simple imputation\n",
    "df['age'] = df['age'].fillna(df['age'].median())\n",
    "df['embarked'] = df['embarked'].fillna(df['embarked'].mode()[0])\n",
    "\n",
    "# One-hot encode categorical features\n",
    "df = pd.get_dummies(df, columns=['sex','embarked'], drop_first=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffa3258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test split and Random Forest training\n",
    "X = df.drop('survived', axis=1)\n",
    "y = df['survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb889e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed evaluation\n",
    "print('\\nClassification Report:\\n')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f62f38",
   "metadata": {},
   "source": [
    "## Feature importance\n",
    "Check which features the Random Forest found most useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9948f5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model.feature_importances_\n",
    "feat_importance = pd.Series(importances, index=X.columns).sort_values(ascending=False)\n",
    "feat_importance\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "feat_importance.plot(kind='bar')\n",
    "plt.title('Feature Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b11add",
   "metadata": {},
   "source": [
    "## Conclusion & How to run in Google Colab\n",
    "- This notebook uses seaborn's built-in Titanic dataset and a Random Forest classifier to predict survival.\n",
    "\n",
    "To open in Google Colab:\n",
    "1. Save this file to your computer from the link below.\n",
    "2. Go to **https://colab.research.google.com/**\n",
    "3. Click **File > Upload notebook** and select the `.ipynb` file.\n",
    "\n",
    "Optional improvements:\n",
    "- Use cross-validation and hyperparameter search (GridSearchCV / RandomizedSearchCV).\n",
    "- Try other models (Logistic Regression, XGBoost).\n",
    "- Add pipelines (sklearn.pipeline) and scaling.\n",
    "- Use more feature engineering (title extraction from names, family size feature, etc.)."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
